{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building blocks: fully connected layers, convolutional layers and pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why not use a regular deep neural network with fully connected layers for Image Recoginition?    \n",
    "Deep net works fine for small images(e.g. MNIST), it breaks down for larger images because of the huge number of parameters.    \n",
    "CNNs solve this problem using partially connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"mark\">receptive field</span>: fh,fw e.g fh,fw=3,3    \n",
    "A neuron located in row i, column j of a given layer is connected to the output of previous layer located in rows from i to i+fh-1 and j to j+fw-1.    \n",
    "\n",
    "Zero padding: It's common to add zeros around the inputs.    \n",
    "\n",
    "Space out the receptive fields: the distance between two consecutive receptive fields is called the <span class=\"mark\">stride</span>. \n",
    "if the stride is sh,sw, then i,j correspond to from i*sh to i*sh+fh-1 and from j*sw to j*sw+fw-1.    \n",
    "If sh,sw=1,1 and Zero padding, the height and width are same as the height and width the previous layer.    \n",
    "If sh,sw>1,1 and Zero padding, the height and width are smaller than the height and width the previous layer.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter\n",
    "A neuron's weights can be represented as a small image the size of the receptive field.    \n",
    "a set of weights-->filter\n",
    "vertical line filter    \n",
    "horizontal line filter    \n",
    "During training, a CNN finds the most useful filters for its task, and it learns to combine them into more complex patterns.\n",
    "A layer full of neurons using the same filter gives <span class=\"mark\">a feature map</span>. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Multiple Feature Maps\n",
    "3D convolutional layer   \n",
    "It is composed of serveral feature maps of equal sizes.    \n",
    "Within one feature map, all neurons share same parameters, but different feature maps may have different parameters.    \n",
    "\n",
    "The fact that all neurons in a feature map share the same parameter means that once the CNN has learned to recognize a pattern in one location, it can recognize it in any ohter <span class=\"mark\">location</span>.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling Layer\n",
    "The goal is to subsample the input image in order to reduce the computational load, memeory usage and the number of parameters, thereby limiting the risk of overfitting.    \n",
    "A pooling neuron has no weights; all it does is aggregate the inputs using an aggregation function such as max or mean.    \n",
    "max pooling layer:only the max input value in each kernal makes it to the next layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Architectures\n",
    "Typical CNN architectures stack a few convolutional layers(each one generally followed by a ReLu layer), then a pooling layers, then another few convolutional layers(+ReLu), then another pooling layer, and so one.    \n",
    "\n",
    "The image get smaller and smaller as it progresses throught the network, but it also typically gets deeper and deeper.    \n",
    "At the top of the stack, a regular feedforward neural network is added, composed of a few fully connected layers(+ReLus), and the final layer outputs the prediction(like softmax layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common mistake is to use convolution kernels that are too large(a lot of parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting thing:\n",
    "https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/tutorials/deepdream/deepdream.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
